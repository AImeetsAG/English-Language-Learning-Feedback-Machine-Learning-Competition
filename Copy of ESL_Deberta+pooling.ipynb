{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1D9obSPYPXqK8gVRu4q-LuhEZNxSMRoxH","timestamp":1670393576793}],"mount_file_id":"1D9obSPYPXqK8gVRu4q-LuhEZNxSMRoxH","authorship_tag":"ABX9TyP8batefVdP3S8Z4GXkNrkK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d3e2c19ae3cd4dbbb337c518745da65d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33672dffd3ee41cdb2fb919ea761244a","IPY_MODEL_d62165927c13426cb5c7759292311e77","IPY_MODEL_4156a70f8fa042a586af33915c956728"],"layout":"IPY_MODEL_dbe380cbadae4a29921db12b749b8bb5"}},"33672dffd3ee41cdb2fb919ea761244a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdb70489cc6a49e6899d354f4f3e88c3","placeholder":"​","style":"IPY_MODEL_c9c3cb1c989a40d6a051829b39b9db91","value":"Downloading tokenizer_config.json: 100%"}},"d62165927c13426cb5c7759292311e77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_506650a974f648e9b393b9ddb6ec7977","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ae69478512f480a8e55b6f5557824a9","value":52}},"4156a70f8fa042a586af33915c956728":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db752381743a41c18341cd44d1a17ddc","placeholder":"​","style":"IPY_MODEL_627641f565754d94ab241452b3e8590e","value":" 52.0/52.0 [00:00&lt;00:00, 1.10kB/s]"}},"dbe380cbadae4a29921db12b749b8bb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdb70489cc6a49e6899d354f4f3e88c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9c3cb1c989a40d6a051829b39b9db91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"506650a974f648e9b393b9ddb6ec7977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ae69478512f480a8e55b6f5557824a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db752381743a41c18341cd44d1a17ddc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"627641f565754d94ab241452b3e8590e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6368680e06034773996d73c5459cdcda":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a8ec63901f741d0ac13c45eeeee3af6","IPY_MODEL_b83bcc810c094f8d9079d320b37b2879","IPY_MODEL_097b3ea5e8eb4405af683621211cf70f"],"layout":"IPY_MODEL_a2051eff13ce4f5f8fdeb9ca9745dc68"}},"5a8ec63901f741d0ac13c45eeeee3af6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de879538704f4b86b3b2f373356f37e0","placeholder":"​","style":"IPY_MODEL_85bea89f8c4f4f44a162bf571fe9c574","value":"Downloading config.json: 100%"}},"b83bcc810c094f8d9079d320b37b2879":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb9aa3f0d72649e7a4a0929a82f1235f","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d915dcbd0bba4172838dc2a6aa116ccb","value":579}},"097b3ea5e8eb4405af683621211cf70f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4ea6da9907140c48e644fe759607e05","placeholder":"​","style":"IPY_MODEL_e5f64e7035d948fd8455aa7a9df9f5e1","value":" 579/579 [00:00&lt;00:00, 16.7kB/s]"}},"a2051eff13ce4f5f8fdeb9ca9745dc68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de879538704f4b86b3b2f373356f37e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85bea89f8c4f4f44a162bf571fe9c574":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb9aa3f0d72649e7a4a0929a82f1235f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d915dcbd0bba4172838dc2a6aa116ccb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4ea6da9907140c48e644fe759607e05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5f64e7035d948fd8455aa7a9df9f5e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b2ee145a058437ebee5817d569eb51a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_092f12c3abdd4edcbbda41d9b3911692","IPY_MODEL_fbb2c9bfc13c4d0fa9a5b8232a2e8e2f","IPY_MODEL_5fae2b45235e433abb81566571fbf4b6"],"layout":"IPY_MODEL_5ed0624871d041c6ba3882e1f1aa8798"}},"092f12c3abdd4edcbbda41d9b3911692":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc364654353f4cb6b57dbf77331c3135","placeholder":"​","style":"IPY_MODEL_f6bbce50081449539619b88344427fbe","value":"Downloading spm.model: 100%"}},"fbb2c9bfc13c4d0fa9a5b8232a2e8e2f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_688b2fe055304a2ba2d3b36062a8590b","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70f71d2ec4bb4feda680254e4bac448e","value":2464616}},"5fae2b45235e433abb81566571fbf4b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d8b7d5c09c944589a60827a67268fe6","placeholder":"​","style":"IPY_MODEL_894997a5deab408191d2a1ccc543a067","value":" 2.35M/2.35M [00:00&lt;00:00, 18.8MB/s]"}},"5ed0624871d041c6ba3882e1f1aa8798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc364654353f4cb6b57dbf77331c3135":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6bbce50081449539619b88344427fbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"688b2fe055304a2ba2d3b36062a8590b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70f71d2ec4bb4feda680254e4bac448e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d8b7d5c09c944589a60827a67268fe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"894997a5deab408191d2a1ccc543a067":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb16d3ffa3184648932779be53ab5f95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d189f3b11b94edeadb1741d5bcbf34e","IPY_MODEL_bdbfb074c744456da86ff32416227bf1","IPY_MODEL_2663042748ad432db205b3f0df297497"],"layout":"IPY_MODEL_cdd2d52f4d174bd299d1cb464c5f7450"}},"0d189f3b11b94edeadb1741d5bcbf34e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4360683742b84ca492ffc87130cd6a43","placeholder":"​","style":"IPY_MODEL_807860fd2ccc4792b28fabe8e4e6845d","value":"100%"}},"bdbfb074c744456da86ff32416227bf1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f5de89b3e3447c8873a6e9b695b28fa","max":3945,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4efd4c16eac4162b438e43f3b842040","value":3945}},"2663042748ad432db205b3f0df297497":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08d220383b0c4f0f9ccd6ce0423fc5ae","placeholder":"​","style":"IPY_MODEL_0b46f3bae04747edb1bb08d1566de0b4","value":" 3945/3945 [00:14&lt;00:00, 253.56it/s]"}},"cdd2d52f4d174bd299d1cb464c5f7450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4360683742b84ca492ffc87130cd6a43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"807860fd2ccc4792b28fabe8e4e6845d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f5de89b3e3447c8873a6e9b695b28fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4efd4c16eac4162b438e43f3b842040":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"08d220383b0c4f0f9ccd6ce0423fc5ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b46f3bae04747edb1bb08d1566de0b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31ea1de1846b41fbb90b7a153ae6be7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8249bf267ca4467a91dee1a4374a10af","IPY_MODEL_b8b25c75a2f24fc78b527880b8330c7d","IPY_MODEL_c2eec70fc5db4992848865cb3386d753"],"layout":"IPY_MODEL_28ca40660c364d13b9e9fb9b336a8dfa"}},"8249bf267ca4467a91dee1a4374a10af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6531224a9034a47be98b83611d68964","placeholder":"​","style":"IPY_MODEL_92e30a87d95c4a559161d2b1b8084d74","value":"Downloading pytorch_model.bin: 100%"}},"b8b25c75a2f24fc78b527880b8330c7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34addf326b6440b7907fb8d5f75eb3fb","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a44f223d9de411685a1506f1329cb44","value":371146213}},"c2eec70fc5db4992848865cb3386d753":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07fcba50019c4a1da056d7a4b283ead7","placeholder":"​","style":"IPY_MODEL_e53c48ef50e64a0eb4fcdabb98d6710f","value":" 354M/354M [00:07&lt;00:00, 68.8MB/s]"}},"28ca40660c364d13b9e9fb9b336a8dfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6531224a9034a47be98b83611d68964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92e30a87d95c4a559161d2b1b8084d74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34addf326b6440b7907fb8d5f75eb3fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a44f223d9de411685a1506f1329cb44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07fcba50019c4a1da056d7a4b283ead7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e53c48ef50e64a0eb4fcdabb98d6710f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["**Directory Settings**"],"metadata":{"id":"trLbCP-Jdp4r"}},{"cell_type":"code","source":["import os\n","OUTPUT_DIR = '/content/drive/MyDrive/Colab Notebooks/Erdos Fall 2022' # change directory when running on local machine"],"metadata":{"id":"nzvE-WG1dkh9","executionInfo":{"status":"ok","timestamp":1670392886407,"user_tz":360,"elapsed":10,"user":{"displayName":"A Chand","userId":"12771142845664675938"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install transformers==4.21.2\n","!pip install tokenizers==0.12.1\n","!pip install sentencepiece"],"metadata":{"id":"_RsPbUamdyVo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670392915594,"user_tz":360,"elapsed":29195,"user":{"displayName":"A Chand","userId":"12771142845664675938"}},"outputId":"5c544ff7-8921-4f12-c296-e705f70e91a1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.21.2\n","  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 15.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (4.64.1)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 53.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.21.2) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.2) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.2) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.12.1 transformers-4.21.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers==0.12.1 in /usr/local/lib/python3.8/dist-packages (0.12.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 28.2 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"markdown","source":["**Custom Configuration class** </br>\n","https://huggingface.co/docs/transformers/main_classes/configuration"],"metadata":{"id":"65DSjYiLd_vh"}},{"cell_type":"code","source":["class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=20\n","    num_workers=5\n","    model=\"microsoft/deberta-v3-base\"\n","    gradient_checkpointing=True\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=2\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=2\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=10\n","    trn_fold= range(n_fold)\n","    train=True"],"metadata":{"id":"BFgNnZ5Bd0s8","executionInfo":{"status":"ok","timestamp":1670392915595,"user_tz":360,"elapsed":25,"user":{"displayName":"A Chand","userId":"12771142845664675938"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**Libraries**"],"metadata":{"id":"rKUr80OwfCus"}},{"cell_type":"code","source":["import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","os.system('pip install iterative-stratification==0.1.7')\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","import tokenizers\n","import transformers\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9eDi8MmofDYA","executionInfo":{"status":"ok","timestamp":1670392931776,"user_tz":360,"elapsed":16203,"user":{"displayName":"A Chand","userId":"12771142845664675938"}},"outputId":"1851563d-c1a2-4cfd-e13e-24d99219d3f7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["env: TOKENIZERS_PARALLELISM=true\n"]}]},{"cell_type":"markdown","source":["**Utils**"],"metadata":{"id":"po72P5MBh1F6"}},{"cell_type":"code","source":["def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"],"metadata":{"id":"YVgJhsuIeeK4","executionInfo":{"status":"ok","timestamp":1670392931777,"user_tz":360,"elapsed":6,"user":{"displayName":"A Chand","userId":"12771142845664675938"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["**Data Loading**"],"metadata":{"id":"bFYdlmjEjYLx"}},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train_new.csv')\n","print(f\"df.shape: {df.shape}\")\n","display(df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"9fC8N5PLh4dz","executionInfo":{"status":"ok","timestamp":1670392932378,"user_tz":360,"elapsed":606,"user":{"displayName":"A Chand","userId":"12771142845664675938"}},"outputId":"780fb8d1-ffd5-4be9-b27d-b154eec4ec40"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["df.shape: (3945, 8)\n"]},{"output_type":"display_data","data":{"text/plain":["        text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n","0  0016926B079C  I think that students would benefit from learn...       3.5     3.5         3.0          3.0      4.0          3.0\n","1  0022683E9EA5  When a problem is a change you have to let it ...       2.5     2.5         3.0          2.0      2.0          2.5\n","2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0     3.5         3.0          3.0      3.0          2.5\n","3  003885A45F42  The best time in life is when you become yours...       4.5     4.5         4.5          4.5      4.0          5.0\n","4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5     3.0         3.0          3.0      2.5          2.5"],"text/html":["\n","  <div id=\"df-9c84677f-3d48-4897-8c4c-e51499697c91\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0016926B079C</td>\n","      <td>I think that students would benefit from learn...</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0022683E9EA5</td>\n","      <td>When a problem is a change you have to let it ...</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00299B378633</td>\n","      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003885A45F42</td>\n","      <td>The best time in life is when you become yours...</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0049B1DF5CCC</td>\n","      <td>Small act of kindness can impact in other peop...</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c84677f-3d48-4897-8c4c-e51499697c91')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9c84677f-3d48-4897-8c4c-e51499697c91 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9c84677f-3d48-4897-8c4c-e51499697c91');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","source":["**CV Split**"],"metadata":{"id":"rkpuX_Gtjihz"}},{"cell_type":"code","source":["# ====================================================\n","# CV split\n","# ====================================================\n","Fold = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=404)\n","for n, (df_index, val_index) in enumerate(Fold.split(df, df[CFG.target_cols])):\n","    df.loc[val_index, 'fold'] = int(n)\n","df['fold'] = df['fold'].astype(int)\n","display(df.groupby('fold').size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"XrG8NUcUjfKL","executionInfo":{"status":"ok","timestamp":1670392932550,"user_tz":360,"elapsed":176,"user":{"displayName":"A Chand","userId":"12771142845664675938"}},"outputId":"1397f16b-b21e-4c06-cb83-f327bee73989"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    394\n","1    395\n","2    395\n","3    394\n","4    395\n","5    394\n","6    394\n","7    394\n","8    395\n","9    395\n","dtype: int64"]},"metadata":{}}]},{"cell_type":"markdown","source":["**Tokenizer**"],"metadata":{"id":"DYrvORLfnX9B"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(CFG.model) # we used deberta tokenizer\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer # saved to configuration class"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["d3e2c19ae3cd4dbbb337c518745da65d","33672dffd3ee41cdb2fb919ea761244a","d62165927c13426cb5c7759292311e77","4156a70f8fa042a586af33915c956728","dbe380cbadae4a29921db12b749b8bb5","bdb70489cc6a49e6899d354f4f3e88c3","c9c3cb1c989a40d6a051829b39b9db91","506650a974f648e9b393b9ddb6ec7977","3ae69478512f480a8e55b6f5557824a9","db752381743a41c18341cd44d1a17ddc","627641f565754d94ab241452b3e8590e","6368680e06034773996d73c5459cdcda","5a8ec63901f741d0ac13c45eeeee3af6","b83bcc810c094f8d9079d320b37b2879","097b3ea5e8eb4405af683621211cf70f","a2051eff13ce4f5f8fdeb9ca9745dc68","de879538704f4b86b3b2f373356f37e0","85bea89f8c4f4f44a162bf571fe9c574","cb9aa3f0d72649e7a4a0929a82f1235f","d915dcbd0bba4172838dc2a6aa116ccb","f4ea6da9907140c48e644fe759607e05","e5f64e7035d948fd8455aa7a9df9f5e1","9b2ee145a058437ebee5817d569eb51a","092f12c3abdd4edcbbda41d9b3911692","fbb2c9bfc13c4d0fa9a5b8232a2e8e2f","5fae2b45235e433abb81566571fbf4b6","5ed0624871d041c6ba3882e1f1aa8798","cc364654353f4cb6b57dbf77331c3135","f6bbce50081449539619b88344427fbe","688b2fe055304a2ba2d3b36062a8590b","70f71d2ec4bb4feda680254e4bac448e","7d8b7d5c09c944589a60827a67268fe6","894997a5deab408191d2a1ccc543a067"]},"id":"fRXBqpwonI9K","executionInfo":{"status":"ok","timestamp":1670392936611,"user_tz":360,"elapsed":4073,"user":{"displayName":"A Chand","userId":"12771142845664675938"}},"outputId":"37beeca9-06ea-4187-eb8c-421b99d71510"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3e2c19ae3cd4dbbb337c518745da65d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6368680e06034773996d73c5459cdcda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b2ee145a058437ebee5817d569eb51a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"markdown","source":["**Max length**"],"metadata":{"id":"ot_z7YjwnyPx"}},{"cell_type":"code","source":["lengths = []\n","for text in tqdm(df['full_text'].values, total=len(df)):\n","    length = len(tokenizer(text, add_special_tokens=True)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths)\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["fb16d3ffa3184648932779be53ab5f95","0d189f3b11b94edeadb1741d5bcbf34e","bdbfb074c744456da86ff32416227bf1","2663042748ad432db205b3f0df297497","cdd2d52f4d174bd299d1cb464c5f7450","4360683742b84ca492ffc87130cd6a43","807860fd2ccc4792b28fabe8e4e6845d","8f5de89b3e3447c8873a6e9b695b28fa","d4efd4c16eac4162b438e43f3b842040","08d220383b0c4f0f9ccd6ce0423fc5ae","0b46f3bae04747edb1bb08d1566de0b4"]},"id":"rd5er14indOl","executionInfo":{"status":"ok","timestamp":1670392951541,"user_tz":360,"elapsed":14937,"user":{"displayName":"A Chand","userId":"12771142845664675938"}},"outputId":"0fc5ab57-7a07-4da5-af58-9f932ee1ba0e"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3945 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb16d3ffa3184648932779be53ab5f95"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_len: 2713\n","INFO:__main__:max_len: 2713\n"]}]},{"cell_type":"code","source":["# example\n","tokenizer(\"I love NLP. I hate NLP\", add_special_tokens=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g07mDLrBoMUH","executionInfo":{"status":"ok","timestamp":1670392951547,"user_tz":360,"elapsed":15,"user":{"displayName":"A Chand","userId":"12771142845664675938"}},"outputId":"7bb0f157-463b-4751-ee8a-68446df5b553"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [1, 273, 472, 40903, 260, 273, 3254, 40903, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["**Dataset**"],"metadata":{"id":"XIlW8asbpdIa"}},{"cell_type":"code","source":["def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text, \n","        return_tensors=None, \n","        add_special_tokens=True, \n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['full_text'].values\n","        self.labels = df[cfg.target_cols].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","    \n","# collate finds the max length in the batch, and truncates every row to its length. This is to speed up training\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs"],"metadata":{"id":"-AM8i6HFoUuq","executionInfo":{"status":"ok","timestamp":1670392951549,"user_tz":360,"elapsed":15,"user":{"displayName":"A Chand","userId":"12771142845664675938"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#example\n","prepare_input(CFG, \"I love NLP. I hate NLP.\") #converted to tensor and padded zeros to max length"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TlAik7NjqE5p","executionInfo":{"status":"ok","timestamp":1670392951728,"user_tz":360,"elapsed":194,"user":{"displayName":"A Chand","userId":"12771142845664675938"}},"outputId":"731bd721-b740-4bee-88ad-f19d165b6c06"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([  1, 273, 472,  ...,   0,   0,   0]), 'token_type_ids': tensor([0, 0, 0,  ..., 0, 0, 0]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0])}"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["**Model**"],"metadata":{"id":"qhLQonq7yyCe"}},{"cell_type":"code","source":["class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, 6)\n","        self._init_weights(self.fc)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"],"metadata":{"id":"NMgtgChLq9r5","executionInfo":{"status":"ok","timestamp":1670392951763,"user_tz":360,"elapsed":65,"user":{"displayName":"A Chand","userId":"12771142845664675938"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["#sentence= \"I love NLP.\" #we didn't add cls and sep here.\n","attention_mask1= torch.tensor([1,1,1,0,0]) # 1's for texts and special tokens. 0's for padding.\n","input_mask_expanded1 = attention_mask1.unsqueeze(-1).expand([5,4]).float() # matrix the size of hidden state\n","last_hidden_state1= torch.tensor([[2,4.5,5,1],[4,1,2,.2],[1,1,2,1],[0.1,2,6,1],[1,1,1,1]]) #sequence of hidden states at the output of the last layer\n","#https://huggingface.co/docs/transformers/main_classes/output\n","sum_embeddings1 = torch.sum(last_hidden_state1 * input_mask_expanded1, 1)\n","sum_mask1 = input_mask_expanded1.sum(1)\n","sum_mask2 = torch.clamp(sum_mask1, min=1e-9)\n","mean_embeddings1 = sum_embeddings1 / sum_mask2\n","\n","display(\"attention_mask:\",attention_mask1)\n","display(\"input_mask_expanded:\", input_mask_expanded1 )\n","display(\"last_hidden_state:\", last_hidden_state1)\n","display(\"sum_embeddings:\", sum_embeddings1)\n","display(\"sum_mask:\", sum_mask1)\n","display(\"sum_mask2:\", sum_mask2)\n","display(\"mean_embeddings:\", mean_embeddings1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"Lvc8kMhuveBX","executionInfo":{"status":"ok","timestamp":1670392951901,"user_tz":360,"elapsed":202,"user":{"displayName":"A Chand","userId":"12771142845664675938"}},"outputId":"daaa7383-df49-4684-c8f1-b1445178dfd0"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["'attention_mask:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tensor([1, 1, 1, 0, 0])"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'input_mask_expanded:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [0., 0., 0., 0.],\n","        [0., 0., 0., 0.]])"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'last_hidden_state:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tensor([[2.0000, 4.5000, 5.0000, 1.0000],\n","        [4.0000, 1.0000, 2.0000, 0.2000],\n","        [1.0000, 1.0000, 2.0000, 1.0000],\n","        [0.1000, 2.0000, 6.0000, 1.0000],\n","        [1.0000, 1.0000, 1.0000, 1.0000]])"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'sum_embeddings:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tensor([12.5000,  7.2000,  5.0000,  0.0000,  0.0000])"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'sum_mask:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tensor([4., 4., 4., 0., 0.])"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'sum_mask2:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tensor([4.0000e+00, 4.0000e+00, 4.0000e+00, 1.0000e-09, 1.0000e-09])"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'mean_embeddings:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tensor([3.1250, 1.8000, 1.2500, 0.0000, 0.0000])"]},"metadata":{}}]},{"cell_type":"markdown","source":["**Loss**"],"metadata":{"id":"zQ2gV1z0GzE6"}},{"cell_type":"code","source":["class RMSELoss(nn.Module):\n","    def __init__(self, reduction='mean', eps=1e-9):\n","        super().__init__()\n","        self.mse = nn.MSELoss(reduction='none')\n","        self.reduction = reduction\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true):\n","        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss"],"metadata":{"id":"KDLHTAte4LxX","executionInfo":{"status":"ok","timestamp":1670392951902,"user_tz":360,"elapsed":10,"user":{"displayName":"A Chand","userId":"12771142845664675938"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["**Helper Function**"],"metadata":{"id":"-pdrBtwqHakd"}},{"cell_type":"code","source":["class AverageMeter(object):\n","    #Computes and stores the average and current value\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","      \n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions"],"metadata":{"id":"AVObqY1J0EPH","executionInfo":{"status":"ok","timestamp":1670392952038,"user_tz":360,"elapsed":146,"user":{"displayName":"A Chand","userId":"12771142845664675938"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["**Train Loop**"],"metadata":{"id":"kGizOusSP_Xp"}},{"cell_type":"code","source":["def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # loader\n","\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size * 2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # model & optimizer\n"," \n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # scheduler\n","\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # loop\n","    criterion = nn.SmoothL1Loss(reduction='mean') # RMSELoss(reduction=\"mean\")\n","    \n","    best_score = np.inf\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score, scores = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","        \n","        if best_score > score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"],"metadata":{"id":"KQq28D4-QB2q","executionInfo":{"status":"ok","timestamp":1670392952039,"user_tz":360,"elapsed":12,"user":{"displayName":"A Chand","userId":"12771142845664675938"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target_cols].values\n","        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","        score, scores = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(df, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","    "],"metadata":{"id":"UPElqSr1QcNI","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["31ea1de1846b41fbb90b7a153ae6be7b","8249bf267ca4467a91dee1a4374a10af","b8b25c75a2f24fc78b527880b8330c7d","c2eec70fc5db4992848865cb3386d753","28ca40660c364d13b9e9fb9b336a8dfa","f6531224a9034a47be98b83611d68964","92e30a87d95c4a559161d2b1b8084d74","34addf326b6440b7907fb8d5f75eb3fb","2a44f223d9de411685a1506f1329cb44","07fcba50019c4a1da056d7a4b283ead7","e53c48ef50e64a0eb4fcdabb98d6710f"]},"outputId":"656c79e9-a91d-4a5c-8e44-ee4b1147d443"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/354M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31ea1de1846b41fbb90b7a153ae6be7b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1775] Elapsed 0m 29s (remain 884m 21s) Loss: 2.4241(2.4241) Grad: 13.7957  LR: 0.00002000  \n","Epoch: [1][20/1775] Elapsed 8m 23s (remain 700m 34s) Loss: 0.0871(0.9423) Grad: 5.3333  LR: 0.00002000  \n"]}]}]}