{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nG5cxCUaDRB8"
   },
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vA1BN-ArFasq"
   },
   "source": [
    "Sources:\n",
    "https://towardsdatascience.com/checking-grammar-with-bert-and-ulmfit-1f59c718fe75\n",
    "https://gist.github.com/sayakmisra/dbb06efec99e760cf9e5d197175ad9c5#file-grammar-checker-bert-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9335,
     "status": "ok",
     "timestamp": 1667763805197,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "0iOvDR59DVfN",
    "outputId": "5025f3a6-002f-47e3-af84-257dc42ac7da"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8318,
     "status": "ok",
     "timestamp": 1667763816018,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "zHy6pz6sDXG_",
    "outputId": "8e9213a3-9f01-4779-ab8c-6dc7bf3d6754"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xHP0LnwFWQB"
   },
   "source": [
    "Package from: https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10986,
     "status": "ok",
     "timestamp": 1667763829294,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "1HoTdNVQDXPY",
    "outputId": "2fab07cc-a857-4e01-920a-dce4c7daac46"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFttOoE6Fvqx"
   },
   "source": [
    "# Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Pk5ewA9F8qE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wckR5UGDXRn"
   },
   "outputs": [],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./Dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "executionInfo": {
     "elapsed": 126,
     "status": "ok",
     "timestamp": 1667763851855,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "ONLP1VDqGOMD",
    "outputId": "bbc7f4f6-2733-4780-b261-cbe356f27b90"
   },
   "outputs": [],
   "source": [
    "# Report the number of essays in test set.\n",
    "print('Number of test essays: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTx08GE8bHFS"
   },
   "outputs": [],
   "source": [
    "text = df['full_text'].apply(lambda x: x.replace('\\r\\n\\r\\n', ' ') and x.replace('\\n\\n', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0ZHU23Dbzb2"
   },
   "source": [
    "# Import Grammar Checker BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3650,
     "status": "ok",
     "timestamp": 1667763859558,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "TacHemb9bsnL",
    "outputId": "8c5796b8-f5bd-4735-a242-63cbfeb16372"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "output_dir = \"./model_save/\"\n",
    "\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8168,
     "status": "ok",
     "timestamp": 1667763868897,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "aiRnyzNIbsnM",
    "outputId": "d53e3bac-1ee0-416c-f5e0-5bfbad56d978"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puM_FzSucDqP"
   },
   "source": [
    "# Create Grammar Dataframe for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44243,
     "status": "ok",
     "timestamp": 1667763982833,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "TBNWHARFebZs",
    "outputId": "205dd26b-4280-414b-a83b-c7bd286d5567"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YEMraU8efGv"
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nX7WWrSXM6vS"
   },
   "outputs": [],
   "source": [
    "grammar_correct_ratio = []\n",
    "sentence_number = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1667764112854,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "9hVVYfrXOCoh",
    "outputId": "145cbd78-b4a6-4b04-b7d0-6e40e974ff6d"
   },
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "  print('Running on essay ', i+1, '/',len(text))\n",
    "\n",
    "  sentences = [sentence for sentence in tokenize.sent_tokenize(text[i])]\n",
    "  encoded_dict = tokenizer.batch_encode_plus(\n",
    "                          sentences,                      # Sentence to encode.\n",
    "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                          max_length = 64,           # Pad & truncate all sentences.\n",
    "                          pad_to_max_length = True,\n",
    "                          return_attention_mask = True,   # Construct attn. masks.\n",
    "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "      \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_id = encoded_dict['input_ids']\n",
    "      \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_mask = encoded_dict['attention_mask']\n",
    "  input_id = torch.LongTensor(input_id)\n",
    "  attention_mask = torch.LongTensor(attention_mask)\n",
    "\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model_loaded = model_loaded.to(device)\n",
    "  input_id = input_id.to(device)\n",
    "  attention_mask = attention_mask.to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    # Forward pass, calculate logit predictions\n",
    "    outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "  index = logits.argmax(dim=1)\n",
    "\n",
    "  sentence_number.append(len(sentences))\n",
    "  grammar_correct_ratio.append(torch.sum(index).item()/len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1667764121344,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "pUEX6iJbe9jm",
    "outputId": "f721bcfc-153f-4ede-c7eb-dc6b093c9245"
   },
   "outputs": [],
   "source": [
    "sentence_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1667764123345,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "o9cHhdxirbAR",
    "outputId": "c124e496-b297-48b8-e5ee-15863dcd3165"
   },
   "outputs": [],
   "source": [
    "# check the list of ratio\n",
    "grammar_correct_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utgOxsXTPPPJ"
   },
   "outputs": [],
   "source": [
    "df_grammar = pd.DataFrame({'cleaned_full_text':text, 'sentence_number': sentence_number, 'ratio_grammar_correct_sentences': grammar_correct_ratio })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1667764128062,
     "user": {
      "displayName": "Moyi Tian",
      "userId": "16731155409516969374"
     },
     "user_tz": 300
    },
    "id": "Yo1_8TCmPPKM",
    "outputId": "7ad49c88-6e89-40fa-e48b-0362839ee122"
   },
   "outputs": [],
   "source": [
    "df_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9F6N-PU-RWwu"
   },
   "outputs": [],
   "source": [
    "# Save data to csv\n",
    "df_grammar.to_csv('./grammar_test.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
