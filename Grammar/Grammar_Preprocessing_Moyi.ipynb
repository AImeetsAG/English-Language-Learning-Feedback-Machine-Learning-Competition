{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TSaki_sgFlJM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT"
      ],
      "metadata": {
        "id": "nG5cxCUaDRB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources:\n",
        "https://towardsdatascience.com/checking-grammar-with-bert-and-ulmfit-1f59c718fe75\n",
        "https://gist.github.com/sayakmisra/dbb06efec99e760cf9e5d197175ad9c5#file-grammar-checker-bert-ipynb"
      ],
      "metadata": {
        "id": "vA1BN-ArFasq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iOvDR59DVfN",
        "outputId": "49d45d30-0789-424b-9d4e-4938dd8c7b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHy6pz6sDXG_",
        "outputId": "76e7326d-53e8-46b4-a0a1-710c080bb0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Package from: https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "id": "_xHP0LnwFWQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HoTdNVQDXPY",
        "outputId": "c710c40f-0f67-45a8-e129-29a041cd78f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 46.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 73.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "zFttOoE6Fvqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8Pk5ewA9F8qE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6H4sMmlGrIL",
        "outputId": "6aa30db8-058c-46e4-83cf-916ad678b46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To unmount your Google Drive:\n",
        "# drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "bl0NuyPpUbZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Erdos Fall 2022/Dataset/train.csv\")"
      ],
      "metadata": {
        "id": "6wckR5UGDXRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the number of essays in train set.\n",
        "print('Number of training essays: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "ONLP1VDqGOMD",
        "outputId": "2d476d66-6e4d-428b-cbf2-d9656fd9f06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training essays: 3,911\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           text_id                                          full_text  \\\n",
              "1764  8593D649EBE4  Dear, TEACHER_NAME\\n\\nI know that us student a...   \n",
              "3508  EF47AB98271A  Do you agree or disagree with the impression a...   \n",
              "1618  7B0430EDACBA  I agree that having a positive attitude is the...   \n",
              "1642  7CBB1B6F4E25  Having electives classes can be a great opport...   \n",
              "198   0EEE49F99224  Some people believe that you don't identifying...   \n",
              "2598  C0B30026B439  Something I would like to accomplish is being ...   \n",
              "1667  7EA986233EDA  One of minister Winston Churchill most famous ...   \n",
              "1896  8EEA38B2E6CD  Generic_Name is working hard to be owner of hi...   \n",
              "3631  F4C52358CE03  In this reasons from Churchill's statement. I ...   \n",
              "2897  D190133EDD2B  Dear council\\n\\nI think the city council shoul...   \n",
              "\n",
              "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  \n",
              "1764       3.0     2.5         3.0          3.0      3.0          3.0  \n",
              "3508       3.0     3.0         4.0          3.5      3.0          3.0  \n",
              "1618       4.0     3.0         3.5          3.5      3.5          3.5  \n",
              "1642       3.5     3.5         4.0          4.0      3.5          3.0  \n",
              "198        2.5     2.5         2.5          3.5      2.5          2.5  \n",
              "2598       2.5     2.5         3.0          3.0      3.0          3.0  \n",
              "1667       3.5     2.5         3.5          3.0      3.0          3.0  \n",
              "1896       3.0     3.0         3.0          2.5      2.5          2.0  \n",
              "3631       2.5     2.5         2.5          2.0      2.5          2.5  \n",
              "2897       3.0     3.0         2.5          2.5      2.0          2.5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-131f93fb-1d1c-4382-8286-256b6a674c82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1764</th>\n",
              "      <td>8593D649EBE4</td>\n",
              "      <td>Dear, TEACHER_NAME\\n\\nI know that us student a...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3508</th>\n",
              "      <td>EF47AB98271A</td>\n",
              "      <td>Do you agree or disagree with the impression a...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>7B0430EDACBA</td>\n",
              "      <td>I agree that having a positive attitude is the...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1642</th>\n",
              "      <td>7CBB1B6F4E25</td>\n",
              "      <td>Having electives classes can be a great opport...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>0EEE49F99224</td>\n",
              "      <td>Some people believe that you don't identifying...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2598</th>\n",
              "      <td>C0B30026B439</td>\n",
              "      <td>Something I would like to accomplish is being ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1667</th>\n",
              "      <td>7EA986233EDA</td>\n",
              "      <td>One of minister Winston Churchill most famous ...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>8EEA38B2E6CD</td>\n",
              "      <td>Generic_Name is working hard to be owner of hi...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3631</th>\n",
              "      <td>F4C52358CE03</td>\n",
              "      <td>In this reasons from Churchill's statement. I ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2897</th>\n",
              "      <td>D190133EDD2B</td>\n",
              "      <td>Dear council\\n\\nI think the city council shoul...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-131f93fb-1d1c-4382-8286-256b6a674c82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-131f93fb-1d1c-4382-8286-256b6a674c82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-131f93fb-1d1c-4382-8286-256b6a674c82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['full_text'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "mECnpDu6ECpI",
        "outputId": "c246af6a-e674-4f89-e31e-f9bc54a3291f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\\n\\nThe hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and stay home and you wont need to stress about what to wear.\\n\\nmost students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. when u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go.\\n\\nwhen your home your comfortable and you pay attention. it gives then an advantage to be smarter and even pass there classmates on class work. public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. that causes students to fail and they may repeat the class.              \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['full_text'][5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "pLvHrgboOB_I",
        "outputId": "ba5ad672-c99e-483f-d0ab-82437dfc2bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Dear Principal,\\r\\n\\r\\nOur school should have a community center. The reasons why, are so students can learn what our community needs, how to make our community better place, and why is community important for students to know. Its a great to have a community center to know how we can make things better.\\r\\n\\r\\nStudents think community center takes their time away. but they have to learn what our community needs. students will participate in a group of students making a list what our community needs, therefore students will learn what our community needs! students will present their list of things our community needs! due to that students will be giving extra credit for the ones who have low grades!\\r\\n\\r\\nSome students don't participate because their friends say its waste of time. it would not be waste of time when you get to know how our community can be a better place for us. students should know that the program is about our own lives, because if our community is bad well our lives are going to be bad. due to that students will want to participate and will want to make our community a better place for us.\\r\\n\\r\\nsome student might say why is the community important anyways, were fine nothing is wrong. but when get to know what our community is, they would want to know about and would want to participate and know why is our community important. students will receive a good grade if they participate in this community because is like an extra credit. due to that their friends would want to enjoy the program because their friend told them about it.\\r\\n\\r\\nso principal the community center will be a great place for students to learn lots of things. so i guess this will be a good idea for our school. students will learn what our community needs, how to make our community a better place, and why is our community important!\\r\\n\\r\\nSincerely, STUDENT_NAME\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = df['full_text'].apply(lambda x: x.replace('\\r\\n\\r\\n', ' ') and x.replace('\\n\\n', ' '))"
      ],
      "metadata": {
        "id": "76Fn71MaPDgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTCMXB3xPlsS",
        "outputId": "0cb9b757-786c-4945-80d2-f32a5c241c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3911,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list grammar scores\n",
        "labels = df.grammar.values"
      ],
      "metadata": {
        "id": "UIN0U7tMMSdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeYgSz3KMSWc",
        "outputId": "448d56ce-acaa-4757-f9c6-5a18c02435c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3911,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Grammar Checker BERT Model"
      ],
      "metadata": {
        "id": "0TC-Lt-7GN6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/Colab Notebooks/Erdos Fall 2022/model_save/\"\n",
        "\n",
        "print(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNRrNRMYDoCN",
        "outputId": "cc13281c-2525-4804-c12f-69ed00188176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 74.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.24.0\n",
            "/content/drive/MyDrive/Colab Notebooks/Erdos Fall 2022/model_save/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWwupaKQEMZ8",
        "outputId": "48646f90-d020-47fc-b637-fb111523f41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try on first essay"
      ],
      "metadata": {
        "id": "TSaki_sgFlJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JMCZtELH5N_",
        "outputId": "283424ce-fc99-4245-e05c-d2ac911d59a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tokenize"
      ],
      "metadata": {
        "id": "aHIJiUEwEMS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay1_sentences = [sentence for sentence in tokenize.sent_tokenize(text[0])]"
      ],
      "metadata": {
        "id": "OCpo0yzxIilt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(essay1_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd8qn5NmKAmv",
        "outputId": "82896336-b021-426e-f54f-7f723659a5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dict = tokenizer.batch_encode_plus(\n",
        "                        essay1_sentences,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "# Add the encoded sentence to the list.    \n",
        "input_id = encoded_dict['input_ids']\n",
        "    \n",
        "# And its attention mask (simply differentiates padding from non-padding).\n",
        "attention_mask = encoded_dict['attention_mask']\n",
        "input_id = torch.LongTensor(input_id)\n",
        "attention_mask = torch.LongTensor(attention_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLRgntnITlm",
        "outputId": "b86590ef-742c-4fba-9637-bd6dbebd47b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_loaded = model_loaded.to(device)\n",
        "input_id = input_id.to(device)\n",
        "attention_mask = attention_mask.to(device)"
      ],
      "metadata": {
        "id": "CaxMw3JEIxpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  # Forward pass, calculate logit predictions\n",
        "  outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azETL-FQJAHz",
        "outputId": "77540564-5a26-4f1c-e2fc-7f424feba8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[-1.4535,  2.3197],\n",
              "        [ 1.4277, -2.5745],\n",
              "        [-1.9283,  3.2056],\n",
              "        [-1.9442,  3.1001],\n",
              "        [-1.9300,  2.7581],\n",
              "        [-0.7864,  0.9893],\n",
              "        [-1.6461,  2.9197],\n",
              "        [-1.4238,  2.1689],\n",
              "        [-1.4116,  2.9467],\n",
              "        [-1.8151,  2.9699],\n",
              "        [ 0.1897, -0.5348],\n",
              "        [ 1.2897, -2.6996],\n",
              "        [ 0.3602, -0.8343],\n",
              "        [ 0.8457, -0.9150],\n",
              "        [ 1.1205, -2.2841],\n",
              "        [-1.7858,  2.8251],\n",
              "        [-1.1794,  1.6135],\n",
              "        [-1.5450,  2.8306]], device='cuda:0'), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = outputs[0]\n",
        "index = logits.argmax(dim=1)\n",
        "for id in index:\n",
        "  if id == 1:\n",
        "    print(\"Gramatically correct\")\n",
        "  else:\n",
        "    print(\"Gramatically in-correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DEg7SZvKV6T",
        "outputId": "80a96473-5cc3-49f8-ea5d-d46d69d4811a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gramatically correct\n",
            "Gramatically in-correct\n",
            "Gramatically correct\n",
            "Gramatically correct\n",
            "Gramatically correct\n",
            "Gramatically correct\n",
            "Gramatically correct\n",
            "Gramatically correct\n",
            "Gramatically correct\n",
            "Gramatically correct\n",
            "Gramatically in-correct\n",
            "Gramatically in-correct\n",
            "Gramatically in-correct\n",
            "Gramatically in-correct\n",
            "Gramatically in-correct\n",
            "Gramatically correct\n",
            "Gramatically correct\n",
            "Gramatically correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfpjFLCMMAnX",
        "outputId": "fed7a73e-79ac-4077-9c11-d229d7019ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The number of grammatically correct sentences is ', torch.sum(index).item(), ' out of ', len(essay1_sentences), ' sentences')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6SxV2qBLRjX",
        "outputId": "b64a21b6-8f93-4a89-a3e9-19cada3aa858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of grammatically correct sentences is  12  out of  18  sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Correct ratio is ', torch.sum(index).item()/len(essay1_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMMHM_8gNZJw",
        "outputId": "22ba940d-4ef4-45a3-ff39-43e513cc9225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct ratio is  0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Grammar score is ', labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRtr0niSLyr5",
        "outputId": "6cd4663c-13af-4ad4-c439-183fd9b53898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar score is  4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a list of ratios corresponding grammatically correct sentences for essays in trainset"
      ],
      "metadata": {
        "id": "7uQwViSKNqGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammar_correct_ratio = []"
      ],
      "metadata": {
        "id": "nX7WWrSXM6vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text)):\n",
        "  if i%100 == 0:\n",
        "    print('Running on essay ', i, '/',len(text))\n",
        "  sentences = [sentence for sentence in tokenize.sent_tokenize(text[i])]\n",
        "  encoded_dict = tokenizer.batch_encode_plus(\n",
        "                          sentences,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 64,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "  # Add the encoded sentence to the list.    \n",
        "  input_id = encoded_dict['input_ids']\n",
        "      \n",
        "  # And its attention mask (simply differentiates padding from non-padding).\n",
        "  attention_mask = encoded_dict['attention_mask']\n",
        "  input_id = torch.LongTensor(input_id)\n",
        "  attention_mask = torch.LongTensor(attention_mask)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model_loaded = model_loaded.to(device)\n",
        "  input_id = input_id.to(device)\n",
        "  attention_mask = attention_mask.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  index = logits.argmax(dim=1)\n",
        "\n",
        "  grammar_correct_ratio.append(torch.sum(index).item()/len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hVVYfrXOCoh",
        "outputId": "1e06404e-3b51-4a80-e8a1-de41faae4ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on essay  0 / 3911\n",
            "Running on essay  100 / 3911\n",
            "Running on essay  200 / 3911\n",
            "Running on essay  300 / 3911\n",
            "Running on essay  400 / 3911\n",
            "Running on essay  500 / 3911\n",
            "Running on essay  600 / 3911\n",
            "Running on essay  700 / 3911\n",
            "Running on essay  800 / 3911\n",
            "Running on essay  900 / 3911\n",
            "Running on essay  1000 / 3911\n",
            "Running on essay  1100 / 3911\n",
            "Running on essay  1200 / 3911\n",
            "Running on essay  1300 / 3911\n",
            "Running on essay  1400 / 3911\n",
            "Running on essay  1500 / 3911\n",
            "Running on essay  1600 / 3911\n",
            "Running on essay  1700 / 3911\n",
            "Running on essay  1800 / 3911\n",
            "Running on essay  1900 / 3911\n",
            "Running on essay  2000 / 3911\n",
            "Running on essay  2100 / 3911\n",
            "Running on essay  2200 / 3911\n",
            "Running on essay  2300 / 3911\n",
            "Running on essay  2400 / 3911\n",
            "Running on essay  2500 / 3911\n",
            "Running on essay  2600 / 3911\n",
            "Running on essay  2700 / 3911\n",
            "Running on essay  2800 / 3911\n",
            "Running on essay  2900 / 3911\n",
            "Running on essay  3000 / 3911\n",
            "Running on essay  3100 / 3911\n",
            "Running on essay  3200 / 3911\n",
            "Running on essay  3300 / 3911\n",
            "Running on essay  3400 / 3911\n",
            "Running on essay  3500 / 3911\n",
            "Running on essay  3600 / 3911\n",
            "Running on essay  3700 / 3911\n",
            "Running on essay  3800 / 3911\n",
            "Running on essay  3900 / 3911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the list of ratio\n",
        "grammar_correct_ratio"
      ],
      "metadata": {
        "id": "o9cHhdxirbAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267968bc-34ff-4016-c37f-846495c5afba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6666666666666666,\n",
              " 0.35714285714285715,\n",
              " 0.631578947368421,\n",
              " 0.9166666666666666,\n",
              " 0.0,\n",
              " 0.7,\n",
              " 0.7777777777777778,\n",
              " 0.2727272727272727,\n",
              " 0.391304347826087,\n",
              " 0.1875,\n",
              " 0.5454545454545454,\n",
              " 0.8888888888888888,\n",
              " 0.4,\n",
              " 0.84,\n",
              " 0.8536585365853658,\n",
              " 0.0,\n",
              " 0.1111111111111111,\n",
              " 0.8846153846153846,\n",
              " 0.5384615384615384,\n",
              " 0.8,\n",
              " 0.05263157894736842,\n",
              " 0.45,\n",
              " 0.8333333333333334,\n",
              " 0.6875,\n",
              " 0.9767441860465116,\n",
              " 0.0,\n",
              " 0.13333333333333333,\n",
              " 0.7931034482758621,\n",
              " 0.8,\n",
              " 0.0,\n",
              " 0.72,\n",
              " 0.18181818181818182,\n",
              " 0.6,\n",
              " 0.8611111111111112,\n",
              " 0.9512195121951219,\n",
              " 0.6857142857142857,\n",
              " 0.6071428571428571,\n",
              " 0.7727272727272727,\n",
              " 0.41379310344827586,\n",
              " 0.0,\n",
              " 0.8666666666666667,\n",
              " 0.7692307692307693,\n",
              " 0.1111111111111111,\n",
              " 0.8695652173913043,\n",
              " 0.8571428571428571,\n",
              " 0.5714285714285714,\n",
              " 0.6923076923076923,\n",
              " 0.0,\n",
              " 0.13636363636363635,\n",
              " 0.2903225806451613,\n",
              " 0.24528301886792453,\n",
              " 0.5,\n",
              " 0.8666666666666667,\n",
              " 0.6363636363636364,\n",
              " 0.7435897435897436,\n",
              " 0.7777777777777778,\n",
              " 0.7916666666666666,\n",
              " 0.5555555555555556,\n",
              " 0.6595744680851063,\n",
              " 0.15384615384615385,\n",
              " 0.9545454545454546,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.17391304347826086,\n",
              " 0.0,\n",
              " 0.5625,\n",
              " 0.2857142857142857,\n",
              " 0.5909090909090909,\n",
              " 0.08333333333333333,\n",
              " 0.45454545454545453,\n",
              " 0.4444444444444444,\n",
              " 0.36,\n",
              " 0.7058823529411765,\n",
              " 0.19230769230769232,\n",
              " 0.42105263157894735,\n",
              " 0.5555555555555556,\n",
              " 0.625,\n",
              " 0.4583333333333333,\n",
              " 0.5294117647058824,\n",
              " 0.6428571428571429,\n",
              " 0.6122448979591837,\n",
              " 0.52,\n",
              " 0.625,\n",
              " 0.75,\n",
              " 0.7692307692307693,\n",
              " 0.3333333333333333,\n",
              " 0.25806451612903225,\n",
              " 0.6086956521739131,\n",
              " 0.625,\n",
              " 0.25,\n",
              " 0.7272727272727273,\n",
              " 0.1111111111111111,\n",
              " 0.0,\n",
              " 0.75,\n",
              " 0.25,\n",
              " 0.6842105263157895,\n",
              " 0.6666666666666666,\n",
              " 0.6363636363636364,\n",
              " 0.9302325581395349,\n",
              " 0.6666666666666666,\n",
              " 0.18181818181818182,\n",
              " 0.7692307692307693,\n",
              " 0.38636363636363635,\n",
              " 0.4782608695652174,\n",
              " 0.8333333333333334,\n",
              " 0.0,\n",
              " 0.2,\n",
              " 0.8888888888888888,\n",
              " 0.9354838709677419,\n",
              " 0.7368421052631579,\n",
              " 0.4117647058823529,\n",
              " 0.8461538461538461,\n",
              " 0.6,\n",
              " 0.4090909090909091,\n",
              " 0.0,\n",
              " 0.5,\n",
              " 0.4117647058823529,\n",
              " 0.3888888888888889,\n",
              " 0.42857142857142855,\n",
              " 0.25,\n",
              " 0.8666666666666667,\n",
              " 0.4642857142857143,\n",
              " 0.625,\n",
              " 0.3333333333333333,\n",
              " 0.4782608695652174,\n",
              " 0.0,\n",
              " 0.47368421052631576,\n",
              " 0.8378378378378378,\n",
              " 0.5333333333333333,\n",
              " 0.47058823529411764,\n",
              " 0.9411764705882353,\n",
              " 0.7,\n",
              " 0.043478260869565216,\n",
              " 0.5714285714285714,\n",
              " 0.3333333333333333,\n",
              " 0.6363636363636364,\n",
              " 0.8181818181818182,\n",
              " 0.5,\n",
              " 0.22727272727272727,\n",
              " 0.25,\n",
              " 0.8947368421052632,\n",
              " 0.16666666666666666,\n",
              " 0.6111111111111112,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.7407407407407407,\n",
              " 0.46153846153846156,\n",
              " 0.8571428571428571,\n",
              " 0.6818181818181818,\n",
              " 0.6875,\n",
              " 0.8095238095238095,\n",
              " 0.32142857142857145,\n",
              " 0.25,\n",
              " 0.8461538461538461,\n",
              " 0.46153846153846156,\n",
              " 0.7777777777777778,\n",
              " 0.8181818181818182,\n",
              " 1.0,\n",
              " 0.9090909090909091,\n",
              " 0.8333333333333334,\n",
              " 0.30434782608695654,\n",
              " 0.2857142857142857,\n",
              " 0.8095238095238095,\n",
              " 0.375,\n",
              " 0.7142857142857143,\n",
              " 0.6923076923076923,\n",
              " 0.25,\n",
              " 0.7631578947368421,\n",
              " 0.8108108108108109,\n",
              " 0.16666666666666666,\n",
              " 0.4,\n",
              " 0.36,\n",
              " 0.8181818181818182,\n",
              " 0.7142857142857143,\n",
              " 0.9666666666666667,\n",
              " 0.16666666666666666,\n",
              " 0.1,\n",
              " 0.8181818181818182,\n",
              " 0.0,\n",
              " 0.5263157894736842,\n",
              " 0.8333333333333334,\n",
              " 0.18181818181818182,\n",
              " 0.625,\n",
              " 0.9615384615384616,\n",
              " 0.2222222222222222,\n",
              " 0.3333333333333333,\n",
              " 0.0,\n",
              " 0.6818181818181818,\n",
              " 0.5263157894736842,\n",
              " 0.7692307692307693,\n",
              " 0.4444444444444444,\n",
              " 0.55,\n",
              " 0.75,\n",
              " 0.7692307692307693,\n",
              " 0.26666666666666666,\n",
              " 0.14285714285714285,\n",
              " 0.7777777777777778,\n",
              " 0.95,\n",
              " 0.5,\n",
              " 0.3333333333333333,\n",
              " 0.5,\n",
              " 0.6818181818181818,\n",
              " 0.6875,\n",
              " 0.9523809523809523,\n",
              " 0.625,\n",
              " 0.18181818181818182,\n",
              " 0.5384615384615384,\n",
              " 0.8846153846153846,\n",
              " 0.1111111111111111,\n",
              " 0.2,\n",
              " 0.45454545454545453,\n",
              " 0.0,\n",
              " 0.9,\n",
              " 0.47619047619047616,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.8235294117647058,\n",
              " 0.7647058823529411,\n",
              " 0.7058823529411765,\n",
              " 0.7058823529411765,\n",
              " 0.5833333333333334,\n",
              " 0.7777777777777778,\n",
              " 0.6666666666666666,\n",
              " 0.36363636363636365,\n",
              " 0.375,\n",
              " 1.0,\n",
              " 0.8076923076923077,\n",
              " 0.1111111111111111,\n",
              " 0.0,\n",
              " 0.5357142857142857,\n",
              " 0.375,\n",
              " 0.21212121212121213,\n",
              " 0.7560975609756098,\n",
              " 0.16666666666666666,\n",
              " 0.7272727272727273,\n",
              " 0.041666666666666664,\n",
              " 0.3076923076923077,\n",
              " 0.9333333333333333,\n",
              " 0.125,\n",
              " 0.2608695652173913,\n",
              " 1.0,\n",
              " 0.9375,\n",
              " 0.6666666666666666,\n",
              " 0.7037037037037037,\n",
              " 0.2857142857142857,\n",
              " 0.8333333333333334,\n",
              " 0.4,\n",
              " 0.8888888888888888,\n",
              " 0.1875,\n",
              " 0.5625,\n",
              " 0.9166666666666666,\n",
              " 0.5555555555555556,\n",
              " 1.0,\n",
              " 0.72,\n",
              " 0.0,\n",
              " 0.1111111111111111,\n",
              " 0.9444444444444444,\n",
              " 0.2,\n",
              " 0.9666666666666667,\n",
              " 0.375,\n",
              " 0.8461538461538461,\n",
              " 0.7804878048780488,\n",
              " 0.5454545454545454,\n",
              " 0.23529411764705882,\n",
              " 0.4444444444444444,\n",
              " 0.8888888888888888,\n",
              " 0.625,\n",
              " 0.6538461538461539,\n",
              " 0.38461538461538464,\n",
              " 0.4444444444444444,\n",
              " 0.7037037037037037,\n",
              " 0.48148148148148145,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.8,\n",
              " 0.65,\n",
              " 0.0,\n",
              " 0.8846153846153846,\n",
              " 0.8181818181818182,\n",
              " 0.6153846153846154,\n",
              " 0.55,\n",
              " 0.8888888888888888,\n",
              " 0.375,\n",
              " 0.29411764705882354,\n",
              " 0.9259259259259259,\n",
              " 0.6428571428571429,\n",
              " 0.46153846153846156,\n",
              " 0.5882352941176471,\n",
              " 0.45454545454545453,\n",
              " 0.8076923076923077,\n",
              " 0.25,\n",
              " 0.8695652173913043,\n",
              " 0.6818181818181818,\n",
              " 0.7407407407407407,\n",
              " 0.7083333333333334,\n",
              " 0.0,\n",
              " 0.42857142857142855,\n",
              " 0.1,\n",
              " 0.8,\n",
              " 0.8936170212765957,\n",
              " 0.92,\n",
              " 0.65625,\n",
              " 0.1111111111111111,\n",
              " 0.7368421052631579,\n",
              " 0.8823529411764706,\n",
              " 0.75,\n",
              " 0.6,\n",
              " 0.8571428571428571,\n",
              " 0.7142857142857143,\n",
              " 0.8461538461538461,\n",
              " 0.1111111111111111,\n",
              " 0.39285714285714285,\n",
              " 0.42857142857142855,\n",
              " 0.6666666666666666,\n",
              " 0.24,\n",
              " 0.9285714285714286,\n",
              " 0.8421052631578947,\n",
              " 0.0,\n",
              " 0.5,\n",
              " 0.125,\n",
              " 0.7333333333333333,\n",
              " 0.7142857142857143,\n",
              " 0.7333333333333333,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.7333333333333333,\n",
              " 0.9047619047619048,\n",
              " 0.6153846153846154,\n",
              " 0.1111111111111111,\n",
              " 0.4375,\n",
              " 0.4,\n",
              " 0.6333333333333333,\n",
              " 0.8636363636363636,\n",
              " 0.5555555555555556,\n",
              " 0.7727272727272727,\n",
              " 0.7586206896551724,\n",
              " 0.6666666666666666,\n",
              " 0.7272727272727273,\n",
              " 0.7142857142857143,\n",
              " 0.84,\n",
              " 0.375,\n",
              " 0.8,\n",
              " 0.3333333333333333,\n",
              " 0.6470588235294118,\n",
              " 0.7272727272727273,\n",
              " 0.5,\n",
              " 0.6363636363636364,\n",
              " 0.2,\n",
              " 0.4666666666666667,\n",
              " 0.20833333333333334,\n",
              " 0.0,\n",
              " 0.09090909090909091,\n",
              " 0.19047619047619047,\n",
              " 0.55,\n",
              " 0.4,\n",
              " 0.5,\n",
              " 0.16129032258064516,\n",
              " 0.8928571428571429,\n",
              " 0.7272727272727273,\n",
              " 0.7692307692307693,\n",
              " 0.0,\n",
              " 0.6842105263157895,\n",
              " 0.75,\n",
              " 0.2,\n",
              " 0.2,\n",
              " 0.6458333333333334,\n",
              " 0.2222222222222222,\n",
              " 0.8518518518518519,\n",
              " 0.3181818181818182,\n",
              " 0.2222222222222222,\n",
              " 0.5,\n",
              " 0.7,\n",
              " 0.2608695652173913,\n",
              " 0.2857142857142857,\n",
              " 0.46153846153846156,\n",
              " 0.44,\n",
              " 0.9545454545454546,\n",
              " 0.3157894736842105,\n",
              " 0.3333333333333333,\n",
              " 0.5,\n",
              " 0.5555555555555556,\n",
              " 0.5714285714285714,\n",
              " 0.25,\n",
              " 0.2,\n",
              " 1.0,\n",
              " 0.9454545454545454,\n",
              " 0.5,\n",
              " 0.9230769230769231,\n",
              " 0.5217391304347826,\n",
              " 0.65625,\n",
              " 0.88,\n",
              " 0.0,\n",
              " 0.5454545454545454,\n",
              " 0.4,\n",
              " 0.6153846153846154,\n",
              " 0.75,\n",
              " 0.7894736842105263,\n",
              " 0.9210526315789473,\n",
              " 0.7333333333333333,\n",
              " 0.7272727272727273,\n",
              " 0.8461538461538461,\n",
              " 0.7272727272727273,\n",
              " 0.75,\n",
              " 0.8666666666666667,\n",
              " 0.32,\n",
              " 0.75,\n",
              " 0.17857142857142858,\n",
              " 0.3333333333333333,\n",
              " 0.6071428571428571,\n",
              " 0.6,\n",
              " 0.7222222222222222,\n",
              " 0.9130434782608695,\n",
              " 0.7272727272727273,\n",
              " 0.5714285714285714,\n",
              " 0.3,\n",
              " 0.5555555555555556,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 0.7058823529411765,\n",
              " 0.1111111111111111,\n",
              " 0.125,\n",
              " 0.8518518518518519,\n",
              " 0.8846153846153846,\n",
              " 0.4166666666666667,\n",
              " 0.1,\n",
              " 0.4444444444444444,\n",
              " 0.6086956521739131,\n",
              " 0.25,\n",
              " 0.7333333333333333,\n",
              " 1.0,\n",
              " 0.3181818181818182,\n",
              " 0.375,\n",
              " 0.95,\n",
              " 0.6551724137931034,\n",
              " 0.45454545454545453,\n",
              " 0.8571428571428571,\n",
              " 0.6444444444444445,\n",
              " 0.4,\n",
              " 0.09090909090909091,\n",
              " 0.5555555555555556,\n",
              " 0.6428571428571429,\n",
              " 0.7857142857142857,\n",
              " 0.7272727272727273,\n",
              " 0.3793103448275862,\n",
              " 0.5333333333333333,\n",
              " 0.6190476190476191,\n",
              " 0.8148148148148148,\n",
              " 0.42857142857142855,\n",
              " 0.8461538461538461,\n",
              " 0.64,\n",
              " 0.6428571428571429,\n",
              " 0.8518518518518519,\n",
              " 0.7777777777777778,\n",
              " 0.5555555555555556,\n",
              " 0.7333333333333333,\n",
              " 0.90625,\n",
              " 0.68,\n",
              " 0.6842105263157895,\n",
              " 0.7142857142857143,\n",
              " 0.18181818181818182,\n",
              " 0.7692307692307693,\n",
              " 0.3333333333333333,\n",
              " 0.6111111111111112,\n",
              " 0.8571428571428571,\n",
              " 0.9583333333333334,\n",
              " 0.9,\n",
              " 0.6451612903225806,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 0.2222222222222222,\n",
              " 0.19047619047619047,\n",
              " 0.6842105263157895,\n",
              " 0.7058823529411765,\n",
              " 0.11764705882352941,\n",
              " 0.6829268292682927,\n",
              " 0.37037037037037035,\n",
              " 1.0,\n",
              " 0.6190476190476191,\n",
              " 0.8571428571428571,\n",
              " 0.5555555555555556,\n",
              " 0.9166666666666666,\n",
              " 0.7083333333333334,\n",
              " 0.7777777777777778,\n",
              " 0.78125,\n",
              " 0.7692307692307693,\n",
              " 0.5263157894736842,\n",
              " 0.95,\n",
              " 0.1,\n",
              " 0.9285714285714286,\n",
              " 0.43333333333333335,\n",
              " 0.7058823529411765,\n",
              " 0.9166666666666666,\n",
              " 0.782608695652174,\n",
              " 0.8333333333333334,\n",
              " 0.36363636363636365,\n",
              " 0.25,\n",
              " 0.16666666666666666,\n",
              " 0.7692307692307693,\n",
              " 0.8695652173913043,\n",
              " 0.45454545454545453,\n",
              " 0.9047619047619048,\n",
              " 0.9230769230769231,\n",
              " 0.6666666666666666,\n",
              " 0.75,\n",
              " 0.5714285714285714,\n",
              " 0.6666666666666666,\n",
              " 0.6875,\n",
              " 0.7368421052631579,\n",
              " 0.631578947368421,\n",
              " 0.0,\n",
              " 0.6818181818181818,\n",
              " 0.3076923076923077,\n",
              " 0.4864864864864865,\n",
              " 0.8235294117647058,\n",
              " 0.1111111111111111,\n",
              " 0.4375,\n",
              " 0.43478260869565216,\n",
              " 0.4375,\n",
              " 0.375,\n",
              " 0.4444444444444444,\n",
              " 1.0,\n",
              " 0.5,\n",
              " 0.25,\n",
              " 0.46153846153846156,\n",
              " 0.5,\n",
              " 0.9130434782608695,\n",
              " 0.34782608695652173,\n",
              " 0.2916666666666667,\n",
              " 0.0,\n",
              " 0.7727272727272727,\n",
              " 0.3076923076923077,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.2413793103448276,\n",
              " 0.2222222222222222,\n",
              " 0.4117647058823529,\n",
              " 0.2857142857142857,\n",
              " 0.4418604651162791,\n",
              " 0.7,\n",
              " 0.42857142857142855,\n",
              " 0.6875,\n",
              " 0.35,\n",
              " 0.4782608695652174,\n",
              " 0.8571428571428571,\n",
              " 0.2857142857142857,\n",
              " 0.0,\n",
              " 0.8695652173913043,\n",
              " 0.375,\n",
              " 0.7142857142857143,\n",
              " 0.3684210526315789,\n",
              " 0.2631578947368421,\n",
              " 0.5769230769230769,\n",
              " 0.0,\n",
              " 0.6153846153846154,\n",
              " 0.8888888888888888,\n",
              " 0.625,\n",
              " 0.7419354838709677,\n",
              " 0.8947368421052632,\n",
              " 0.3333333333333333,\n",
              " 0.8125,\n",
              " 0.5714285714285714,\n",
              " 0.5517241379310345,\n",
              " 0.30434782608695654,\n",
              " 0.1111111111111111,\n",
              " 0.375,\n",
              " 0.2222222222222222,\n",
              " 0.7692307692307693,\n",
              " 0.6666666666666666,\n",
              " 0.5714285714285714,\n",
              " 0.9285714285714286,\n",
              " 0.0,\n",
              " 0.3333333333333333,\n",
              " 0.5833333333333334,\n",
              " 0.5,\n",
              " 0.0,\n",
              " 0.6231884057971014,\n",
              " 0.6111111111111112,\n",
              " 0.7692307692307693,\n",
              " 0.42857142857142855,\n",
              " 0.84375,\n",
              " 0.4,\n",
              " 0.8666666666666667,\n",
              " 0.3333333333333333,\n",
              " 0.8,\n",
              " 0.1,\n",
              " 0.4166666666666667,\n",
              " 0.9142857142857143,\n",
              " 0.6363636363636364,\n",
              " 0.35714285714285715,\n",
              " 0.375,\n",
              " 0.3888888888888889,\n",
              " 0.4782608695652174,\n",
              " 0.5,\n",
              " 0.5,\n",
              " 0.8235294117647058,\n",
              " 0.7058823529411765,\n",
              " 0.5714285714285714,\n",
              " 0.4230769230769231,\n",
              " 0.625,\n",
              " 0.9375,\n",
              " 0.375,\n",
              " 0.7,\n",
              " 0.6888888888888889,\n",
              " 0.9285714285714286,\n",
              " 0.22727272727272727,\n",
              " 0.7631578947368421,\n",
              " 0.6875,\n",
              " 0.0,\n",
              " 0.125,\n",
              " 0.5,\n",
              " 0.65,\n",
              " 0.3333333333333333,\n",
              " 0.5,\n",
              " 0.375,\n",
              " 0.7777777777777778,\n",
              " 0.8928571428571429,\n",
              " 0.6538461538461539,\n",
              " 0.2222222222222222,\n",
              " 0.35294117647058826,\n",
              " 0.7272727272727273,\n",
              " 0.7037037037037037,\n",
              " 0.9130434782608695,\n",
              " 0.14285714285714285,\n",
              " 0.5833333333333334,\n",
              " 0.6666666666666666,\n",
              " 0.8888888888888888,\n",
              " 0.7307692307692307,\n",
              " 0.6111111111111112,\n",
              " 0.125,\n",
              " 0.5217391304347826,\n",
              " 0.6857142857142857,\n",
              " 0.7272727272727273,\n",
              " 0.6,\n",
              " 0.4444444444444444,\n",
              " 0.4,\n",
              " 0.6129032258064516,\n",
              " 0.6111111111111112,\n",
              " 0.7142857142857143,\n",
              " 0.6842105263157895,\n",
              " 0.3333333333333333,\n",
              " 0.7058823529411765,\n",
              " 0.0,\n",
              " 0.1111111111111111,\n",
              " 0.4,\n",
              " 0.45454545454545453,\n",
              " 0.8181818181818182,\n",
              " 0.9285714285714286,\n",
              " 0.875,\n",
              " 0.3,\n",
              " 0.2857142857142857,\n",
              " 0.6666666666666666,\n",
              " 0.1,\n",
              " 0.23076923076923078,\n",
              " 0.9705882352941176,\n",
              " 0.95,\n",
              " 0.2222222222222222,\n",
              " 0.1111111111111111,\n",
              " 0.6190476190476191,\n",
              " 0.7647058823529411,\n",
              " 0.14285714285714285,\n",
              " 0.7,\n",
              " 0.7142857142857143,\n",
              " 0.6923076923076923,\n",
              " 0.42857142857142855,\n",
              " 1.0,\n",
              " 0.07692307692307693,\n",
              " 0.8333333333333334,\n",
              " 0.16666666666666666,\n",
              " 0.7222222222222222,\n",
              " 0.7142857142857143,\n",
              " 0.32,\n",
              " 0.8484848484848485,\n",
              " 0.6451612903225806,\n",
              " 0.6,\n",
              " 0.14285714285714285,\n",
              " 1.0,\n",
              " 0.65,\n",
              " 0.9047619047619048,\n",
              " 0.0,\n",
              " 0.6923076923076923,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.6,\n",
              " 0.95,\n",
              " 0.72,\n",
              " 0.48,\n",
              " 0.9375,\n",
              " 0.7222222222222222,\n",
              " 0.46153846153846156,\n",
              " 0.4166666666666667,\n",
              " 0.75,\n",
              " 0.9523809523809523,\n",
              " 0.3888888888888889,\n",
              " 0.4594594594594595,\n",
              " 0.4,\n",
              " 1.0,\n",
              " 0.7333333333333333,\n",
              " 0.5454545454545454,\n",
              " 0.8076923076923077,\n",
              " 0.25,\n",
              " 1.0,\n",
              " 0.5714285714285714,\n",
              " 0.36363636363636365,\n",
              " 0.9473684210526315,\n",
              " 0.9166666666666666,\n",
              " 0.1875,\n",
              " 0.68,\n",
              " 0.375,\n",
              " 0.9583333333333334,\n",
              " 0.3333333333333333,\n",
              " 0.8571428571428571,\n",
              " 0.47058823529411764,\n",
              " 0.7058823529411765,\n",
              " 1.0,\n",
              " 0.5,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.6071428571428571,\n",
              " 0.375,\n",
              " 0.7777777777777778,\n",
              " 0.8947368421052632,\n",
              " 0.15625,\n",
              " 0.8,\n",
              " 0.5,\n",
              " 0.9523809523809523,\n",
              " 0.13333333333333333,\n",
              " 0.5897435897435898,\n",
              " 0.8620689655172413,\n",
              " 0.47058823529411764,\n",
              " 0.7272727272727273,\n",
              " 0.3076923076923077,\n",
              " 0.7692307692307693,\n",
              " 0.6,\n",
              " 0.8888888888888888,\n",
              " 0.75,\n",
              " 0.9333333333333333,\n",
              " 0.4,\n",
              " 0.5833333333333334,\n",
              " 0.5555555555555556,\n",
              " 0.8125,\n",
              " 0.625,\n",
              " 0.0,\n",
              " 0.8648648648648649,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 0.8292682926829268,\n",
              " 0.4,\n",
              " 0.1,\n",
              " 0.45714285714285713,\n",
              " 0.8275862068965517,\n",
              " 0.8,\n",
              " 0.875,\n",
              " 0.5294117647058824,\n",
              " 0.782608695652174,\n",
              " 0.9166666666666666,\n",
              " 0.5333333333333333,\n",
              " 0.8125,\n",
              " 0.36,\n",
              " 0.8695652173913043,\n",
              " 0.2857142857142857,\n",
              " 0.5,\n",
              " 0.8235294117647058,\n",
              " 0.8148148148148148,\n",
              " 0.20833333333333334,\n",
              " 0.24,\n",
              " 0.25,\n",
              " 0.8,\n",
              " 0.9090909090909091,\n",
              " 0.0,\n",
              " 0.3103448275862069,\n",
              " 0.5384615384615384,\n",
              " 0.4166666666666667,\n",
              " 0.0,\n",
              " 0.3076923076923077,\n",
              " 0.75,\n",
              " 0.6346153846153846,\n",
              " 1.0,\n",
              " 0.3,\n",
              " 0.16666666666666666,\n",
              " 0.7142857142857143,\n",
              " 0.7407407407407407,\n",
              " 0.26666666666666666,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7777777777777778,\n",
              " 0.875,\n",
              " 0.92,\n",
              " 0.2727272727272727,\n",
              " 0.9629629629629629,\n",
              " 0.2,\n",
              " 0.3125,\n",
              " 0.7647058823529411,\n",
              " 0.625,\n",
              " 0.3333333333333333,\n",
              " 0.3333333333333333,\n",
              " 0.8,\n",
              " 0.045454545454545456,\n",
              " 0.65,\n",
              " 0.5925925925925926,\n",
              " 0.7575757575757576,\n",
              " 0.0,\n",
              " 0.875,\n",
              " 0.8888888888888888,\n",
              " 0.4,\n",
              " 0.5555555555555556,\n",
              " 0.9411764705882353,\n",
              " 0.26666666666666666,\n",
              " 0.9714285714285714,\n",
              " 0.68,\n",
              " 0.3333333333333333,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.5,\n",
              " 0.5769230769230769,\n",
              " 0.7692307692307693,\n",
              " 0.6086956521739131,\n",
              " 0.35714285714285715,\n",
              " 0.88,\n",
              " 0.7272727272727273,\n",
              " 0.5263157894736842,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.4444444444444444,\n",
              " 0.25,\n",
              " 0.7857142857142857,\n",
              " 0.0,\n",
              " 0.15384615384615385,\n",
              " 0.7058823529411765,\n",
              " 0.9117647058823529,\n",
              " 0.4444444444444444,\n",
              " 0.8125,\n",
              " 0.4444444444444444,\n",
              " 0.7857142857142857,\n",
              " 0.5,\n",
              " 1.0,\n",
              " 0.2857142857142857,\n",
              " 0.9230769230769231,\n",
              " 0.3235294117647059,\n",
              " 0.9523809523809523,\n",
              " 0.8,\n",
              " 0.9090909090909091,\n",
              " 0.35294117647058826,\n",
              " 0.0,\n",
              " 0.3157894736842105,\n",
              " 0.6666666666666666,\n",
              " 0.4666666666666667,\n",
              " 0.6,\n",
              " 0.72,\n",
              " 0.5555555555555556,\n",
              " 0.75,\n",
              " 0.375,\n",
              " 0.8333333333333334,\n",
              " 0.0,\n",
              " 0.7142857142857143,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.7586206896551724,\n",
              " 0.7916666666666666,\n",
              " 0.875,\n",
              " 0.7391304347826086,\n",
              " 0.20833333333333334,\n",
              " 0.5,\n",
              " 0.35294117647058826,\n",
              " 0.6666666666666666,\n",
              " 0.42857142857142855,\n",
              " 0.8695652173913043,\n",
              " 0.5294117647058824,\n",
              " 0.42857142857142855,\n",
              " 0.15384615384615385,\n",
              " 0.4666666666666667,\n",
              " 0.6538461538461539,\n",
              " 0.6363636363636364,\n",
              " 0.8333333333333334,\n",
              " 0.04,\n",
              " 0.6,\n",
              " 0.7692307692307693,\n",
              " 0.75,\n",
              " 0.3333333333333333,\n",
              " 0.4482758620689655,\n",
              " 0.2,\n",
              " 0.7647058823529411,\n",
              " 0.9375,\n",
              " 0.9090909090909091,\n",
              " 0.36363636363636365,\n",
              " 0.2,\n",
              " 0.7647058823529411,\n",
              " 0.6818181818181818,\n",
              " 0.896551724137931,\n",
              " 0.1111111111111111,\n",
              " 0.6,\n",
              " 0.6923076923076923,\n",
              " 0.2,\n",
              " 0.6875,\n",
              " 0.5,\n",
              " 1.0,\n",
              " 0.3,\n",
              " 0.7619047619047619,\n",
              " 0.30303030303030304,\n",
              " 0.8571428571428571,\n",
              " 0.36363636363636365,\n",
              " 0.27586206896551724,\n",
              " 0.8235294117647058,\n",
              " 0.6666666666666666,\n",
              " 0.0,\n",
              " 0.6666666666666666,\n",
              " 0.2,\n",
              " 0.22580645161290322,\n",
              " 0.5555555555555556,\n",
              " 0.8636363636363636,\n",
              " 0.9583333333333334,\n",
              " 1.0,\n",
              " 0.7,\n",
              " 0.6666666666666666,\n",
              " 0.35714285714285715,\n",
              " 0.8214285714285714,\n",
              " 0.7083333333333334,\n",
              " 0.6,\n",
              " 0.18181818181818182,\n",
              " 0.52,\n",
              " 0.6666666666666666,\n",
              " 0.7142857142857143,\n",
              " 0.3333333333333333,\n",
              " 0.1,\n",
              " 0.625,\n",
              " 0.8421052631578947,\n",
              " 0.6785714285714286,\n",
              " 0.4782608695652174,\n",
              " 0.6,\n",
              " 0.6,\n",
              " 0.8928571428571429,\n",
              " 0.0,\n",
              " 0.6923076923076923,\n",
              " 0.5,\n",
              " 0.7666666666666667,\n",
              " 0.0,\n",
              " 0.36363636363636365,\n",
              " 0.6666666666666666,\n",
              " 1.0,\n",
              " 0.05,\n",
              " 0.8928571428571429,\n",
              " 1.0,\n",
              " 0.25,\n",
              " 0.6,\n",
              " 0.5,\n",
              " 0.8571428571428571,\n",
              " 0.7407407407407407,\n",
              " 0.0,\n",
              " 0.75,\n",
              " 0.8181818181818182,\n",
              " 0.9,\n",
              " 0.9333333333333333,\n",
              " 0.5,\n",
              " 0.15384615384615385,\n",
              " 0.36,\n",
              " 0.8333333333333334,\n",
              " 0.9166666666666666,\n",
              " 0.5357142857142857,\n",
              " 0.8181818181818182,\n",
              " 0.125,\n",
              " 0.18181818181818182,\n",
              " 0.2413793103448276,\n",
              " 0.7666666666666667,\n",
              " 0.75,\n",
              " 0.8214285714285714,\n",
              " 0.0,\n",
              " 0.16666666666666666,\n",
              " 0.0,\n",
              " 0.75,\n",
              " 0.8181818181818182,\n",
              " 0.8666666666666667,\n",
              " 0.09090909090909091,\n",
              " 0.30434782608695654,\n",
              " 0.6363636363636364,\n",
              " 0.375,\n",
              " 0.9375,\n",
              " 0.8,\n",
              " 0.6470588235294118,\n",
              " 0.4444444444444444,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 0.45454545454545453,\n",
              " 0.18181818181818182,\n",
              " 1.0,\n",
              " 0.5555555555555556,\n",
              " 0.5714285714285714,\n",
              " 0.5555555555555556,\n",
              " 0.9047619047619048,\n",
              " 0.6086956521739131,\n",
              " 0.5789473684210527,\n",
              " 1.0,\n",
              " 0.16666666666666666,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.5882352941176471,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.25,\n",
              " 0.6428571428571429,\n",
              " 0.4,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_grammar = pd.DataFrame({'cleaned_full_text':text, 'grammar_score': labels, 'ratio_grammar_correct_sentences': grammar_correct_ratio })"
      ],
      "metadata": {
        "id": "utgOxsXTPPPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_grammar"
      ],
      "metadata": {
        "id": "Yo1_8TCmPPKM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "5c451d68-d497-4c89-eeec-63901ba54d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      cleaned_full_text  grammar_score  \\\n",
              "0     I think that students would benefit from learn...            4.0   \n",
              "1     When a problem is a change you have to let it ...            2.0   \n",
              "2     Dear, Principal If u change the school policy ...            3.0   \n",
              "3     The best time in life is when you become yours...            4.0   \n",
              "4     Small act of kindness can impact in other peop...            2.5   \n",
              "...                                                 ...            ...   \n",
              "3906  I believe using cellphones in class for educat...            2.5   \n",
              "3907  Working alone, students do not have to argue w...            3.5   \n",
              "3908  \"A problem is a chance for you to do your best...            3.5   \n",
              "3909  Many people disagree with Albert Schweitzer's ...            4.5   \n",
              "3910  Do you think that failure is the main thing fo...            3.0   \n",
              "\n",
              "      ratio_grammar_correct_sentences  \n",
              "0                            0.666667  \n",
              "1                            0.357143  \n",
              "2                            0.631579  \n",
              "3                            0.916667  \n",
              "4                            0.000000  \n",
              "...                               ...  \n",
              "3906                         0.500000  \n",
              "3907                         0.437500  \n",
              "3908                         0.375000  \n",
              "3909                         1.000000  \n",
              "3910                         0.200000  \n",
              "\n",
              "[3911 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7110397c-8645-40de-9fde-fac90a4f10ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_full_text</th>\n",
              "      <th>grammar_score</th>\n",
              "      <th>ratio_grammar_correct_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dear, Principal If u change the school policy ...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.631579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3906</th>\n",
              "      <td>I believe using cellphones in class for educat...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3907</th>\n",
              "      <td>Working alone, students do not have to argue w...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3908</th>\n",
              "      <td>\"A problem is a chance for you to do your best...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>Many people disagree with Albert Schweitzer's ...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>Do you think that failure is the main thing fo...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3911 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7110397c-8645-40de-9fde-fac90a4f10ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7110397c-8645-40de-9fde-fac90a4f10ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7110397c-8645-40de-9fde-fac90a4f10ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save data to csv in Google Drive\n",
        "df_grammar.to_csv('/content/drive/MyDrive/Colab Notebooks/Erdos Fall 2022/grammar_train.csv')"
      ],
      "metadata": {
        "id": "9F6N-PU-RWwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_number = []"
      ],
      "metadata": {
        "id": "qwi1_zufhpAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text)):\n",
        "  if i%100 == 0:\n",
        "    print('Running on essay ', i+1, '/',len(text))\n",
        "  sentence_number.append(len(tokenize.sent_tokenize(text[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv8IF8ChhhcX",
        "outputId": "47b613c4-cd76-481b-ef86-575291df0eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on essay  1 / 3911\n",
            "Running on essay  101 / 3911\n",
            "Running on essay  201 / 3911\n",
            "Running on essay  301 / 3911\n",
            "Running on essay  401 / 3911\n",
            "Running on essay  501 / 3911\n",
            "Running on essay  601 / 3911\n",
            "Running on essay  701 / 3911\n",
            "Running on essay  801 / 3911\n",
            "Running on essay  901 / 3911\n",
            "Running on essay  1001 / 3911\n",
            "Running on essay  1101 / 3911\n",
            "Running on essay  1201 / 3911\n",
            "Running on essay  1301 / 3911\n",
            "Running on essay  1401 / 3911\n",
            "Running on essay  1501 / 3911\n",
            "Running on essay  1601 / 3911\n",
            "Running on essay  1701 / 3911\n",
            "Running on essay  1801 / 3911\n",
            "Running on essay  1901 / 3911\n",
            "Running on essay  2001 / 3911\n",
            "Running on essay  2101 / 3911\n",
            "Running on essay  2201 / 3911\n",
            "Running on essay  2301 / 3911\n",
            "Running on essay  2401 / 3911\n",
            "Running on essay  2501 / 3911\n",
            "Running on essay  2601 / 3911\n",
            "Running on essay  2701 / 3911\n",
            "Running on essay  2801 / 3911\n",
            "Running on essay  2901 / 3911\n",
            "Running on essay  3001 / 3911\n",
            "Running on essay  3101 / 3911\n",
            "Running on essay  3201 / 3911\n",
            "Running on essay  3301 / 3911\n",
            "Running on essay  3401 / 3911\n",
            "Running on essay  3501 / 3911\n",
            "Running on essay  3601 / 3911\n",
            "Running on essay  3701 / 3911\n",
            "Running on essay  3801 / 3911\n",
            "Running on essay  3901 / 3911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentence_number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPkJRFbxh1W8",
        "outputId": "a85022c7-544f-4f21-8fe6-a03f0913ddbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3911"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_sentence_number = pd.DataFrame({'sentence_number':sentence_number})"
      ],
      "metadata": {
        "id": "fnydePJWh2Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_sentence_number.to_csv('/content/drive/MyDrive/Colab Notebooks/Erdos Fall 2022/grammar_train_sentence_number.csv')"
      ],
      "metadata": {
        "id": "1yGLNOkTiHC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine Train csv"
      ],
      "metadata": {
        "id": "cn3wV2hX_yvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jC8ohx7HiNB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46bdcf73-e4e2-4eac-84ab-a9f6b3f7db80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Erdos Fall 2022/grammar_train.csv', index_col=0)"
      ],
      "metadata": {
        "id": "C0v4bzGdAAyt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Erdos Fall 2022/grammar_train_sentence_number.csv', index_col=0)"
      ],
      "metadata": {
        "id": "chjWKh5KACIw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "G1g7T5oxAHr2",
        "outputId": "f3bf6c55-7f40-475d-bc1e-9854614c46a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   cleaned_full_text  grammar_score  \\\n",
              "0  I think that students would benefit from learn...            4.0   \n",
              "1  When a problem is a change you have to let it ...            2.0   \n",
              "2  Dear, Principal If u change the school policy ...            3.0   \n",
              "3  The best time in life is when you become yours...            4.0   \n",
              "4  Small act of kindness can impact in other peop...            2.5   \n",
              "\n",
              "   ratio_grammar_correct_sentences  \n",
              "0                         0.666667  \n",
              "1                         0.357143  \n",
              "2                         0.631579  \n",
              "3                         0.916667  \n",
              "4                         0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a05ea85-7b95-48d4-ada2-1d3224182732\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_full_text</th>\n",
              "      <th>grammar_score</th>\n",
              "      <th>ratio_grammar_correct_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dear, Principal If u change the school policy ...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.631579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a05ea85-7b95-48d4-ada2-1d3224182732')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a05ea85-7b95-48d4-ada2-1d3224182732 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a05ea85-7b95-48d4-ada2-1d3224182732');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PN1mxBCWAO-n",
        "outputId": "ec9fe405-0a9d-48a2-e0c2-f6694d637378"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentence_number\n",
              "0               18\n",
              "1               14\n",
              "2               19\n",
              "3               36\n",
              "4                3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae8f7bb0-fd1e-417b-b6d3-9f3df4c18639\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae8f7bb0-fd1e-417b-b6d3-9f3df4c18639')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae8f7bb0-fd1e-417b-b6d3-9f3df4c18639 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae8f7bb0-fd1e-417b-b6d3-9f3df4c18639');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_comb = train_1"
      ],
      "metadata": {
        "id": "nYBobmpEAUJz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_comb['sentence_number'] = train_2['sentence_number']"
      ],
      "metadata": {
        "id": "b8vXqxA0AXpb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_comb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "55h6GrFNAfXG",
        "outputId": "f0bcbd84-a7bd-4680-e491-19c5e9e8ab74"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      cleaned_full_text  grammar_score  \\\n",
              "0     I think that students would benefit from learn...            4.0   \n",
              "1     When a problem is a change you have to let it ...            2.0   \n",
              "2     Dear, Principal If u change the school policy ...            3.0   \n",
              "3     The best time in life is when you become yours...            4.0   \n",
              "4     Small act of kindness can impact in other peop...            2.5   \n",
              "...                                                 ...            ...   \n",
              "3906  I believe using cellphones in class for educat...            2.5   \n",
              "3907  Working alone, students do not have to argue w...            3.5   \n",
              "3908  \"A problem is a chance for you to do your best...            3.5   \n",
              "3909  Many people disagree with Albert Schweitzer's ...            4.5   \n",
              "3910  Do you think that failure is the main thing fo...            3.0   \n",
              "\n",
              "      ratio_grammar_correct_sentences  sentence_number  \n",
              "0                            0.666667               18  \n",
              "1                            0.357143               14  \n",
              "2                            0.631579               19  \n",
              "3                            0.916667               36  \n",
              "4                            0.000000                3  \n",
              "...                               ...              ...  \n",
              "3906                         0.500000                6  \n",
              "3907                         0.437500               16  \n",
              "3908                         0.375000                8  \n",
              "3909                         1.000000               21  \n",
              "3910                         0.200000               10  \n",
              "\n",
              "[3911 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1164304e-4d83-400d-9ca3-7a17b5b6074a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_full_text</th>\n",
              "      <th>grammar_score</th>\n",
              "      <th>ratio_grammar_correct_sentences</th>\n",
              "      <th>sentence_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dear, Principal If u change the school policy ...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3906</th>\n",
              "      <td>I believe using cellphones in class for educat...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3907</th>\n",
              "      <td>Working alone, students do not have to argue w...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3908</th>\n",
              "      <td>\"A problem is a chance for you to do your best...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>Many people disagree with Albert Schweitzer's ...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>Do you think that failure is the main thing fo...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3911 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1164304e-4d83-400d-9ca3-7a17b5b6074a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1164304e-4d83-400d-9ca3-7a17b5b6074a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1164304e-4d83-400d-9ca3-7a17b5b6074a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_comb.to_csv('/content/drive/MyDrive/Colab Notebooks/Erdos Fall 2022/grammar_train_comb.csv')"
      ],
      "metadata": {
        "id": "iOp-bRjJAgxc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vqShDfFzApaz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}