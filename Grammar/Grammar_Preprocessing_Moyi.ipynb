{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nG5cxCUaDRB8"
   },
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vA1BN-ArFasq"
   },
   "source": [
    "Sources:\n",
    "https://towardsdatascience.com/checking-grammar-with-bert-and-ulmfit-1f59c718fe75\n",
    "https://gist.github.com/sayakmisra/dbb06efec99e760cf9e5d197175ad9c5#file-grammar-checker-bert-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iOvDR59DVfN",
    "outputId": "49d45d30-0789-424b-9d4e-4938dd8c7b1a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zHy6pz6sDXG_",
    "outputId": "76e7326d-53e8-46b4-a0a1-710c080bb0ce"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xHP0LnwFWQB"
   },
   "source": [
    "Package from: https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HoTdNVQDXPY",
    "outputId": "c710c40f-0f67-45a8-e129-29a041cd78f5"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFttOoE6Fvqx"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Pk5ewA9F8qE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wckR5UGDXRn"
   },
   "outputs": [],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./Dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76Fn71MaPDgu"
   },
   "outputs": [],
   "source": [
    "text = df['full_text'].apply(lambda x: x.replace('\\r\\n\\r\\n', ' ') and x.replace('\\n\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTCMXB3xPlsS",
    "outputId": "0cb9b757-786c-4945-80d2-f32a5c241c14"
   },
   "outputs": [],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIN0U7tMMSdH"
   },
   "outputs": [],
   "source": [
    "# Get the list grammar scores\n",
    "labels = df.grammar.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DeYgSz3KMSWc",
    "outputId": "448d56ce-acaa-4757-f9c6-5a18c02435c1"
   },
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TC-Lt-7GN6l"
   },
   "source": [
    "# Import Grammar Checker BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNRrNRMYDoCN",
    "outputId": "cc13281c-2525-4804-c12f-69ed00188176"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "output_dir = \"./model_save/\"\n",
    "\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWwupaKQEMZ8",
    "outputId": "48646f90-d020-47fc-b637-fb111523f41e"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSaki_sgFlJM"
   },
   "source": [
    "### Try on first essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JMCZtELH5N_",
    "outputId": "283424ce-fc99-4245-e05c-d2ac911d59a1"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHIJiUEwEMS2"
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCpo0yzxIilt"
   },
   "outputs": [],
   "source": [
    "essay1_sentences = [sentence for sentence in tokenize.sent_tokenize(text[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pd8qn5NmKAmv",
    "outputId": "82896336-b021-426e-f54f-7f723659a5d6"
   },
   "outputs": [],
   "source": [
    "len(essay1_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVLRgntnITlm",
    "outputId": "b86590ef-742c-4fba-9637-bd6dbebd47b9"
   },
   "outputs": [],
   "source": [
    "encoded_dict = tokenizer.batch_encode_plus(\n",
    "                        essay1_sentences,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "# Add the encoded sentence to the list.    \n",
    "input_id = encoded_dict['input_ids']\n",
    "    \n",
    "# And its attention mask (simply differentiates padding from non-padding).\n",
    "attention_mask = encoded_dict['attention_mask']\n",
    "input_id = torch.LongTensor(input_id)\n",
    "attention_mask = torch.LongTensor(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaxMw3JEIxpt"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_loaded = model_loaded.to(device)\n",
    "input_id = input_id.to(device)\n",
    "attention_mask = attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azETL-FQJAHz",
    "outputId": "77540564-5a26-4f1c-e2fc-7f424feba8e7"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  # Forward pass, calculate logit predictions\n",
    "  outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DEg7SZvKV6T",
    "outputId": "80a96473-5cc3-49f8-ea5d-d46d69d4811a"
   },
   "outputs": [],
   "source": [
    "logits = outputs[0]\n",
    "index = logits.argmax(dim=1)\n",
    "for id in index:\n",
    "  if id == 1:\n",
    "    print(\"Gramatically correct\")\n",
    "  else:\n",
    "    print(\"Gramatically in-correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UfpjFLCMMAnX",
    "outputId": "fed7a73e-79ac-4077-9c11-d229d7019ba4"
   },
   "outputs": [],
   "source": [
    "type(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6SxV2qBLRjX",
    "outputId": "b64a21b6-8f93-4a89-a3e9-19cada3aa858"
   },
   "outputs": [],
   "source": [
    "print('The number of grammatically correct sentences is ', torch.sum(index).item(), ' out of ', len(essay1_sentences), ' sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMMHM_8gNZJw",
    "outputId": "22ba940d-4ef4-45a3-ff39-43e513cc9225"
   },
   "outputs": [],
   "source": [
    "print('Correct ratio is ', torch.sum(index).item()/len(essay1_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRtr0niSLyr5",
    "outputId": "6cd4663c-13af-4ad4-c439-183fd9b53898"
   },
   "outputs": [],
   "source": [
    "print('Grammar score is ', labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uQwViSKNqGu"
   },
   "source": [
    "## Make a list of ratios corresponding grammatically correct sentences for essays in trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nX7WWrSXM6vS"
   },
   "outputs": [],
   "source": [
    "grammar_correct_ratio = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hVVYfrXOCoh",
    "outputId": "1e06404e-3b51-4a80-e8a1-de41faae4ee5"
   },
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "  if i%100 == 0:\n",
    "    print('Running on essay ', i, '/',len(text))\n",
    "  sentences = [sentence for sentence in tokenize.sent_tokenize(text[i])]\n",
    "  encoded_dict = tokenizer.batch_encode_plus(\n",
    "                          sentences,                      # Sentence to encode.\n",
    "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                          max_length = 64,           # Pad & truncate all sentences.\n",
    "                          pad_to_max_length = True,\n",
    "                          return_attention_mask = True,   # Construct attn. masks.\n",
    "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "      \n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_id = encoded_dict['input_ids']\n",
    "      \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_mask = encoded_dict['attention_mask']\n",
    "  input_id = torch.LongTensor(input_id)\n",
    "  attention_mask = torch.LongTensor(attention_mask)\n",
    "\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model_loaded = model_loaded.to(device)\n",
    "  input_id = input_id.to(device)\n",
    "  attention_mask = attention_mask.to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    # Forward pass, calculate logit predictions\n",
    "    outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "  index = logits.argmax(dim=1)\n",
    "\n",
    "  grammar_correct_ratio.append(torch.sum(index).item()/len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9cHhdxirbAR",
    "outputId": "267968bc-34ff-4016-c37f-846495c5afba"
   },
   "outputs": [],
   "source": [
    "# check the list of ratio\n",
    "grammar_correct_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utgOxsXTPPPJ"
   },
   "outputs": [],
   "source": [
    "df_grammar = pd.DataFrame({'cleaned_full_text':text, 'grammar_score': labels, 'ratio_grammar_correct_sentences': grammar_correct_ratio })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Yo1_8TCmPPKM",
    "outputId": "5c451d68-d497-4c89-eeec-63901ba54d7b"
   },
   "outputs": [],
   "source": [
    "df_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9F6N-PU-RWwu"
   },
   "outputs": [],
   "source": [
    "# Save data to csv\n",
    "df_grammar.to_csv('./grammar_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwi1_zufhpAx"
   },
   "outputs": [],
   "source": [
    "sentence_number = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lv8IF8ChhhcX",
    "outputId": "47b613c4-cd76-481b-ef86-575291df0eeb"
   },
   "outputs": [],
   "source": [
    "for i in range(len(text)):\n",
    "  if i%100 == 0:\n",
    "    print('Running on essay ', i+1, '/',len(text))\n",
    "  sentence_number.append(len(tokenize.sent_tokenize(text[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPkJRFbxh1W8",
    "outputId": "a85022c7-544f-4f21-8fe6-a03f0913ddbb"
   },
   "outputs": [],
   "source": [
    "len(sentence_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnydePJWh2Xa"
   },
   "outputs": [],
   "source": [
    "df_train_sentence_number = pd.DataFrame({'sentence_number':sentence_number})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cn3wV2hX_yvD"
   },
   "source": [
    "## Combine Train csv and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYBobmpEAUJz"
   },
   "outputs": [],
   "source": [
    "train_comb = df_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8vXqxA0AXpb"
   },
   "outputs": [],
   "source": [
    "train_comb['sentence_number'] = df_train_sentence_number['sentence_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "55h6GrFNAfXG",
    "outputId": "f0bcbd84-a7bd-4680-e491-19c5e9e8ab74"
   },
   "outputs": [],
   "source": [
    "train_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOp-bRjJAgxc"
   },
   "outputs": [],
   "source": [
    "train_comb.to_csv('./grammar_train_comb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqShDfFzApaz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TSaki_sgFlJM"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
